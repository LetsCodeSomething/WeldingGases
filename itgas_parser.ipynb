{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w_fKdELb9bZt"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "import xml.etree.ElementTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u6EdDIOB94MM"
      },
      "outputs": [],
      "source": [
        "st_accept = \"text/html\"\n",
        "st_useragent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 12_3_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.4 Safari/605.1.15\"\n",
        "headers = {\n",
        "   \"Accept\": st_accept,\n",
        "   \"User-Agent\": st_useragent\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIDokKuJ997q"
      },
      "outputs": [],
      "source": [
        "ITGAS_BASE_LINK = \"https://it-gas.ru/\"\n",
        "ITGAS_LINKS = [\"oxygen\", \"propane\", \"acetylene\", \"argon\", \"nitrogen\", \"carbon-dioxide\", \"helium\",\n",
        "               \"welding-gas-mixtures\", \"food-gas-mixtures\", \"app-table\", \"mixtures-name\", \"technic-welding\",\n",
        "               \"specifications-gas-mixtures\", \"mig-mag-tig\", \"\"]\n",
        "PANDAS_CRUTCH = \"/content/temp.txt\"\n",
        "\n",
        "#Метод find_all() рекурсивно обходит дерево тегов и возвращает в виде списка\n",
        "#все теги дерева. По этой причине дублируется содержимое вложенных тегов,\n",
        "#например, списков. Чтобы это не происходило, сохраняем во множестве id\n",
        "#обработанных тегов и каждый раз проверяем, обработан ли тег.\n",
        "processed_tags = {}\n",
        "\n",
        "def parse_ul(ul):\n",
        "    ul_elements = ul.children\n",
        "\n",
        "    for i in ul_elements:\n",
        "        if i.name == None or id(i) in processed_tags:\n",
        "            continue\n",
        "\n",
        "        processed_tags.add(id(i))\n",
        "\n",
        "        #Парсер видит символы в нижнем индексе в химических формулах\n",
        "        #как отдельных потомков, потому что используется тег <sub></sub>.\n",
        "        #Этих потомков игнорируем, чтобы не дублировать текст.\n",
        "        subelements = i.children\n",
        "        sublist = None\n",
        "        for j in subelements:\n",
        "            if j.name == \"sub\":\n",
        "                j.decompose()\n",
        "            elif j.name == \"ul\":\n",
        "                sublist = j\n",
        "\n",
        "        if sublist == None:\n",
        "            f.write(\"        \" + re.sub(\" +\", \" \", i.get_text().lstrip().rstrip()) + \"\\n\")\n",
        "        else:\n",
        "            parse_ul(sublist)\n",
        "    f.write(\"\\n\")\n",
        "    processed_tags.add(ul)\n",
        "    return\n",
        "\n",
        "for i in ITGAS_LINKS:\n",
        "    req = requests.get(ITGAS_BASE_LINK + i, headers)\n",
        "    soup = bs(req.text, 'lxml')\n",
        "    processed_tags = set()\n",
        "\n",
        "    #Костыль для Pandas. Скидываем полученный html в файл и ищем в нём все таблицы.\n",
        "    temp_file = open(\"temp.txt\", 'w', encoding=\"utf-8\")\n",
        "    temp_file.write(req.text)\n",
        "    temp_file.close()\n",
        "    tables = pd.read_html(PANDAS_CRUTCH)\n",
        "    table_index = 0\n",
        "\n",
        "    page_title = soup.find(\"div\", attrs={\"class\":\"page-title\"})\n",
        "\n",
        "    element_letter = soup.find(\"div\", attrs={\"class\":\"chW-chemical\"})\n",
        "    element_name = soup.find(\"div\", attrs={\"class\":\"chW-desc\"})\n",
        "\n",
        "    f = open(page_title.text + \".txt\", 'w', encoding=\"utf-8\")\n",
        "    if element_name != None:\n",
        "        f.write(element_name.text + \" - \" + element_letter.text + \"\\n\")\n",
        "\n",
        "    page_info = soup.find(\"div\", attrs={\"class\":\"float-t\"}).find_all()\n",
        "\n",
        "    for j in page_info:\n",
        "        if id(j) in processed_tags:\n",
        "            continue\n",
        "\n",
        "        if j.name == \"h2\":\n",
        "            f.write(j.text + \"\\n\")\n",
        "        elif j.name == \"h3\":\n",
        "            f.write(\"    \" + j.text + \":\\n\")\n",
        "        elif j.name == \"p\":\n",
        "            f.write(re.sub(\" +\", \" \", j.text.lstrip()) + \"\\n\")\n",
        "        elif j.name == \"ul\":\n",
        "            parse_ul(j)\n",
        "        elif j.name == \"table\":\n",
        "            if \"clr-tbl\" not in j[\"class\"]:\n",
        "                f.write(tables[table_index].fillna(value=\"\").map(lambda l: l.replace(\"?\", \"/\")).to_string(index=False,header=False) + \"\\n\\n\")\n",
        "            table_index += 1\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        processed_tags.add(id(j))\n",
        "\n",
        "    #Закрываем файл, чистим список обработанных тегов.\n",
        "    f.close()\n",
        "    processed_tags.clear()\n",
        "\n",
        "    #Можно накинуть задержку, чтобы не ддосить сайт.\n",
        "    time.sleep(4)\n",
        "\n",
        "#Убираем мусор.\n",
        "os.remove(PANDAS_CRUTCH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
